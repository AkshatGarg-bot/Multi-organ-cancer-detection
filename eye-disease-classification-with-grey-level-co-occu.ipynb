{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Eye disease Classification Using Grey Level Co-occurrence Matrix","metadata":{}},{"cell_type":"markdown","source":"## Step for classification\n### 1. Explore Data Image\n### 2. Preprocessing Data\n### 3. Extraction Feature Using Grey level co-occurrence matrix (GLCM)\n### 4. Normalize Data\n### 5. Classification using Machine Learning Alghoritm","metadata":{}},{"cell_type":"markdown","source":"## These Classification Goals is to create model that can classify eye disease","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-02-13T07:26:06.307229Z","iopub.execute_input":"2022-02-13T07:26:06.307835Z","iopub.status.idle":"2022-02-13T07:26:06.319096Z","shell.execute_reply.started":"2022-02-13T07:26:06.307727Z","shell.execute_reply":"2022-02-13T07:26:06.31831Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 1. Explore Image Data","metadata":{}},{"cell_type":"markdown","source":"In these Exploring Image Data i want to make image data ready for feature extraction using GLCM, So i try some image preprocessing to make image is ready for feature extraction\n\nin this explore image data i want to make some changes to image like\n1. Crop image, so unusefull black image can dissapear from image\n2. Resize image, because image data have a big dimension and i large data make a long time when processing so i resize to small image","metadata":{}},{"cell_type":"markdown","source":"These are some packages to show image","metadata":{}},{"cell_type":"code","source":"import cv2 as cv\nimport matplotlib.pyplot as plt\nfrom skimage.feature import greycomatrix, greycoprops","metadata":{"execution":{"iopub.status.busy":"2022-02-13T07:26:06.336931Z","iopub.execute_input":"2022-02-13T07:26:06.337599Z","iopub.status.idle":"2022-02-13T07:26:08.078101Z","shell.execute_reply.started":"2022-02-13T07:26:06.33755Z","shell.execute_reply":"2022-02-13T07:26:08.077004Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Create method to show image, these created to easily show image using matplotlib","metadata":{}},{"cell_type":"code","source":"def show_image(img, cmap='gray'):\n    fig = plt.figure(figsize=(20,20))\n    axes = fig.add_subplot(111)\n    axes.imshow(img, cmap=cmap)","metadata":{"execution":{"iopub.status.busy":"2022-02-13T07:26:08.079743Z","iopub.execute_input":"2022-02-13T07:26:08.080076Z","iopub.status.idle":"2022-02-13T07:26:08.084406Z","shell.execute_reply.started":"2022-02-13T07:26:08.080036Z","shell.execute_reply":"2022-02-13T07:26:08.083752Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Read image using cv and convert image color from BGR(Blue, Green, Red) to RGB(Red, Green, Blue) because cv automatically make image color to BGR, and matplotlib make wierd image color when showing BGR image. So we convert BGR to RGB","metadata":{}},{"cell_type":"code","source":"test_img = cv.imread('../input/cataractdataset/dataset/1_normal/NL_001.png')\ntest_img = cv.cvtColor(test_img, cv.COLOR_BGR2RGB)\nshow_image(test_img)","metadata":{"execution":{"iopub.status.busy":"2022-02-13T07:26:08.085855Z","iopub.execute_input":"2022-02-13T07:26:08.08628Z","iopub.status.idle":"2022-02-13T07:26:09.475605Z","shell.execute_reply.started":"2022-02-13T07:26:08.086241Z","shell.execute_reply":"2022-02-13T07:26:09.474656Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Convert image from RGB to Grayscale, in these stage we convert 3 dimension from RGB to 1 dimensian in Grayscale","metadata":{}},{"cell_type":"code","source":"width, height, dimension = test_img.shape\nprint(f'Width RGB = {width}')\nprint(f'Height RGB = {height}')\nprint(f'Dimension RGB = {dimension}')","metadata":{"execution":{"iopub.status.busy":"2022-02-13T07:26:09.477169Z","iopub.execute_input":"2022-02-13T07:26:09.477446Z","iopub.status.idle":"2022-02-13T07:26:09.483417Z","shell.execute_reply.started":"2022-02-13T07:26:09.477418Z","shell.execute_reply":"2022-02-13T07:26:09.48245Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_img_gray = cv.cvtColor(test_img, cv.COLOR_RGB2GRAY)\nshow_image(test_img_gray)","metadata":{"execution":{"iopub.status.busy":"2022-02-13T07:26:09.484948Z","iopub.execute_input":"2022-02-13T07:26:09.485336Z","iopub.status.idle":"2022-02-13T07:26:10.307109Z","shell.execute_reply.started":"2022-02-13T07:26:09.485297Z","shell.execute_reply":"2022-02-13T07:26:10.306147Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Grayscale image doseant have dimensiaon becasue grayscale image has 1 color that have range from 0 - 255","metadata":{}},{"cell_type":"code","source":"width, height = test_img_gray.shape\nprint(f'Width Grayscale = {width}')\nprint(f'Height Grayscale = {height}')\nprint(f'Image Shape Grayscale {test_img_gray.shape}')","metadata":{"execution":{"iopub.status.busy":"2022-02-13T07:26:10.308161Z","iopub.execute_input":"2022-02-13T07:26:10.308423Z","iopub.status.idle":"2022-02-13T07:26:10.314079Z","shell.execute_reply.started":"2022-02-13T07:26:10.308397Z","shell.execute_reply":"2022-02-13T07:26:10.313097Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Thresholding Image (Binary Image) from grayscale that have a color range from 0-255 to Threshold Image that have color 0 or 1","metadata":{}},{"cell_type":"code","source":"test_img_thresh = cv.adaptiveThreshold(test_img_gray,255,cv.ADAPTIVE_THRESH_GAUSSIAN_C, cv.THRESH_BINARY_INV,11,3)\nshow_image(test_img_thresh)","metadata":{"execution":{"iopub.status.busy":"2022-02-13T07:26:10.315303Z","iopub.execute_input":"2022-02-13T07:26:10.31557Z","iopub.status.idle":"2022-02-13T07:26:11.197498Z","shell.execute_reply.started":"2022-02-13T07:26:10.315544Z","shell.execute_reply":"2022-02-13T07:26:11.196501Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Cropping Image so unusefull black color dissapeaer from image and i can get the Region of Interest (ROI) of this Image","metadata":{}},{"cell_type":"code","source":"cnts = cv.findContours(test_img_thresh, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\ncnts = cnts[0] if len(cnts) == 2 else cnts[1]\ncnts = sorted(cnts, key=cv.contourArea, reverse=True)\nfor c in cnts:\n    x,y,w,h = cv.boundingRect(c)\n    test_img_ROI = test_img[y:y+h, x:x+w]\n    break\nshow_image(test_img_ROI)","metadata":{"execution":{"iopub.status.busy":"2022-02-13T07:26:11.20032Z","iopub.execute_input":"2022-02-13T07:26:11.200611Z","iopub.status.idle":"2022-02-13T07:26:12.939607Z","shell.execute_reply.started":"2022-02-13T07:26:11.200581Z","shell.execute_reply":"2022-02-13T07:26:12.93843Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Because i crop image from original RGB color so these ROI image have 3 dimensions","metadata":{}},{"cell_type":"code","source":"width, height, dimension = test_img_ROI.shape\nprint(f'Width = {width}')\nprint(f'Height = {height}')\nprint(f'Dimension = {dimension}')","metadata":{"execution":{"iopub.status.busy":"2022-02-13T07:26:12.941549Z","iopub.execute_input":"2022-02-13T07:26:12.941984Z","iopub.status.idle":"2022-02-13T07:26:12.947857Z","shell.execute_reply.started":"2022-02-13T07:26:12.941948Z","shell.execute_reply":"2022-02-13T07:26:12.94674Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Resizing image becase 1600x1600 is to large when processing, i resize to 400x400 by divided by 4","metadata":{}},{"cell_type":"code","source":"test_img_ROI_resize = cv.resize(test_img_ROI, (int(width/4), int(height/4)))\nshow_image(test_img_ROI_resize)","metadata":{"execution":{"iopub.status.busy":"2022-02-13T07:26:12.949397Z","iopub.execute_input":"2022-02-13T07:26:12.950017Z","iopub.status.idle":"2022-02-13T07:26:14.064845Z","shell.execute_reply.started":"2022-02-13T07:26:12.949976Z","shell.execute_reply":"2022-02-13T07:26:14.063726Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Check the reized image that have been resized","metadata":{}},{"cell_type":"code","source":"width, height, dimension = test_img_ROI_resize.shape\nprint(f'Width = {width}')\nprint(f'Height = {height}')\nprint(f'Dimension = {dimension}')","metadata":{"execution":{"iopub.status.busy":"2022-02-13T07:26:14.066153Z","iopub.execute_input":"2022-02-13T07:26:14.066461Z","iopub.status.idle":"2022-02-13T07:26:14.071674Z","shell.execute_reply.started":"2022-02-13T07:26:14.066432Z","shell.execute_reply":"2022-02-13T07:26:14.07051Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Convert resizing image to grayscale because when extraction feature with GLCM image should have 1 dimensions like grayscale","metadata":{}},{"cell_type":"code","source":"test_img_ROI_resize_gray = cv.cvtColor(test_img_ROI_resize, cv.COLOR_RGB2GRAY)\nshow_image(test_img_ROI_resize_gray)","metadata":{"execution":{"iopub.status.busy":"2022-02-13T07:26:14.073335Z","iopub.execute_input":"2022-02-13T07:26:14.073684Z","iopub.status.idle":"2022-02-13T07:26:14.786451Z","shell.execute_reply.started":"2022-02-13T07:26:14.073612Z","shell.execute_reply":"2022-02-13T07:26:14.785722Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Test image to feture extraction with GLCM","metadata":{}},{"cell_type":"code","source":"def glcm_feature(matrix_coocurrence, featureName):\n    feature = greycoprops(matrix_coocurrence, featureName)\n    result = np.average(feature)\n    return result\ndistance = 10\nteta = 90\n\ncontrast_test = []\nhomogeneity_test = []\nenergy_test = []\ncorrelation_test = []\n\n\nglcm = greycomatrix(test_img_ROI_resize_gray, [distance], [teta], levels=256, symmetric=True, normed=True)\ncontrast_test.append(glcm_feature(glcm, 'contrast'))\nhomogeneity_test.append(glcm_feature(glcm, 'homogeneity'))\nenergy_test.append(glcm_feature(glcm, 'energy'))\ncorrelation_test.append(glcm_feature(glcm, 'correlation'))\n\nprint(f'Homogenity : {homogeneity_test[0]}')\nprint(f'Correlation : {correlation_test[0]}')\nprint(f'Energy : {energy_test[0]}')\nprint(f'Contrast : {contrast_test[0]}')","metadata":{"execution":{"iopub.status.busy":"2022-02-13T07:26:14.787484Z","iopub.execute_input":"2022-02-13T07:26:14.787915Z","iopub.status.idle":"2022-02-13T07:26:14.801476Z","shell.execute_reply.started":"2022-02-13T07:26:14.787883Z","shell.execute_reply":"2022-02-13T07:26:14.800763Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. Preprocessing Image","metadata":{}},{"cell_type":"markdown","source":"After i explore some image to be image test, and have some preprocessing image like cropping and resize. i make method to gather all preprocessing step to make image ready to feature extraction","metadata":{}},{"cell_type":"code","source":"def preprocessingImage(image):\n    test_img = cv.cvtColor(image, cv.COLOR_BGR2RGB)\n    test_img_gray = cv.cvtColor(test_img, cv.COLOR_RGB2GRAY)\n    test_img_thresh = cv.adaptiveThreshold(test_img_gray,255,cv.ADAPTIVE_THRESH_GAUSSIAN_C, cv.THRESH_BINARY_INV,11,3)\n    cnts = cv.findContours(test_img_thresh, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n    cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n    cnts = sorted(cnts, key=cv.contourArea, reverse=True)\n    for c in cnts:\n        x,y,w,h = cv.boundingRect(c)\n        test_img_ROI = test_img[y:y+h, x:x+w]\n        break\n    test_img_ROI_resize = cv.resize(test_img_ROI, (width, height))\n    test_img_ROI_resize_gray = cv.cvtColor(test_img_ROI_resize, cv.COLOR_RGB2GRAY)\n    \n    return test_img_ROI_resize_gray","metadata":{"execution":{"iopub.status.busy":"2022-02-13T07:26:14.802575Z","iopub.execute_input":"2022-02-13T07:26:14.803035Z","iopub.status.idle":"2022-02-13T07:26:14.810835Z","shell.execute_reply.started":"2022-02-13T07:26:14.803006Z","shell.execute_reply":"2022-02-13T07:26:14.809895Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. Feature Extraction","metadata":{}},{"cell_type":"markdown","source":"Create some variable that used for feature extraction","metadata":{}},{"cell_type":"code","source":"file_normal = 301\nfile_cataract = 101\nfile_glaucoma = 102\nfile_retina = 101\nwidth, height = 400, 400\ndistance = 10\nteta = 90\ndata_eye = np.zeros((5, 601))\ncount = 0\nindextable = ['contrast', 'homogenity', 'energy', 'correlation', 'Label']\n\nnormal_dataset_path = '../input/cataractdataset/dataset/1_normal/'\ncataract_dataset_path = '../input/cataractdataset/dataset/2_cataract/'\nglaucoma_dataset_path = '../input/cataractdataset/dataset/2_glaucoma/'\nretina_dataset_path = '../input/cataractdataset/dataset/3_retina_disease/'","metadata":{"execution":{"iopub.status.busy":"2022-02-13T07:26:14.812221Z","iopub.execute_input":"2022-02-13T07:26:14.812566Z","iopub.status.idle":"2022-02-13T07:26:14.825929Z","shell.execute_reply.started":"2022-02-13T07:26:14.812536Z","shell.execute_reply":"2022-02-13T07:26:14.825008Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"in these feature extraction i split these processiong based on label and i used 10 distance and 90 teta for GLCM feature extraction","metadata":{}},{"cell_type":"code","source":"for file in range(1, file_normal):\n    contrast = []\n    homogeneity = []\n    energy = []\n    correlation = []\n    label = 0\n    image = cv.imread(f'{normal_dataset_path}/NL_{str(file).zfill(3)}.png')\n    img = preprocessingImage(image)\n    \n    glcm = greycomatrix(img, [distance], [teta], levels=256, symmetric=True, normed=True)\n    contrast.append(glcm_feature(glcm, 'contrast'))\n    homogeneity.append(glcm_feature(glcm, 'homogeneity'))\n    energy.append(glcm_feature(glcm, 'energy'))\n    correlation.append(glcm_feature(glcm, 'correlation'))\n    \n    data_eye[0, count] = contrast[0]\n    data_eye[1, count] = homogeneity[0]\n    data_eye[2, count] = energy[0]\n    data_eye[3, count] = correlation[0]\n    data_eye[4, count] = label\n    \n    count += 1","metadata":{"execution":{"iopub.status.busy":"2022-02-13T07:26:14.827432Z","iopub.execute_input":"2022-02-13T07:26:14.827868Z","iopub.status.idle":"2022-02-13T07:26:58.206918Z","shell.execute_reply.started":"2022-02-13T07:26:14.827823Z","shell.execute_reply":"2022-02-13T07:26:58.205914Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Testing if the feature extraction is succesful","metadata":{}},{"cell_type":"code","source":"data_eye","metadata":{"execution":{"iopub.status.busy":"2022-02-13T07:26:58.208272Z","iopub.execute_input":"2022-02-13T07:26:58.208666Z","iopub.status.idle":"2022-02-13T07:26:58.215887Z","shell.execute_reply.started":"2022-02-13T07:26:58.208611Z","shell.execute_reply":"2022-02-13T07:26:58.21481Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for file in range(1, file_cataract):\n    contrast = []\n    homogeneity = []\n    energy = []\n    correlation = []\n    label = 1\n    image = cv.imread(f'{cataract_dataset_path}/cataract_{str(file).zfill(3)}.png')\n    img = preprocessingImage(image)\n    \n    glcm = greycomatrix(img, [distance], [teta], levels=256, symmetric=True, normed=True)\n    contrast.append(glcm_feature(glcm, 'contrast'))\n    homogeneity.append(glcm_feature(glcm, 'homogeneity'))\n    energy.append(glcm_feature(glcm, 'energy'))\n    correlation.append(glcm_feature(glcm, 'correlation'))\n    \n    data_eye[0, count] = contrast[0]\n    data_eye[1, count] = homogeneity[0]\n    data_eye[2, count] = energy[0]\n    data_eye[3, count] = correlation[0]\n    data_eye[4, count] = label\n    \n    count += 1","metadata":{"execution":{"iopub.status.busy":"2022-02-13T07:26:58.217342Z","iopub.execute_input":"2022-02-13T07:26:58.217638Z","iopub.status.idle":"2022-02-13T07:27:12.725014Z","shell.execute_reply.started":"2022-02-13T07:26:58.217597Z","shell.execute_reply":"2022-02-13T07:27:12.72408Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for file in range(1, file_glaucoma):\n    contrast = []\n    homogeneity = []\n    energy = []\n    correlation = []\n    label = 2\n    image = cv.imread(f'{glaucoma_dataset_path}/Glaucoma_{str(file).zfill(3)}.png')\n    img = preprocessingImage(image)\n    \n    glcm = greycomatrix(img, [distance], [teta], levels=256, symmetric=True, normed=True)\n    contrast.append(glcm_feature(glcm, 'contrast'))\n    homogeneity.append(glcm_feature(glcm, 'homogeneity'))\n    energy.append(glcm_feature(glcm, 'energy'))\n    correlation.append(glcm_feature(glcm, 'correlation'))\n    \n    data_eye[0, count] = contrast[0]\n    data_eye[1, count] = homogeneity[0]\n    data_eye[2, count] = energy[0]\n    data_eye[3, count] = correlation[0]\n    data_eye[4, count] = label\n    \n    count += 1","metadata":{"execution":{"iopub.status.busy":"2022-02-13T07:27:12.726143Z","iopub.execute_input":"2022-02-13T07:27:12.726417Z","iopub.status.idle":"2022-02-13T07:27:27.375148Z","shell.execute_reply.started":"2022-02-13T07:27:12.726389Z","shell.execute_reply":"2022-02-13T07:27:27.374153Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for file in range(1, file_retina):\n    contrast = []\n    homogeneity = []\n    energy = []\n    correlation = []\n    label = 3\n    image = cv.imread(f'{retina_dataset_path}/Retina_{str(file).zfill(3)}.png')\n    img = preprocessingImage(image)\n    \n    glcm = greycomatrix(img, [distance], [teta], levels=256, symmetric=True, normed=True)\n    contrast.append(glcm_feature(glcm, 'contrast'))\n    homogeneity.append(glcm_feature(glcm, 'homogeneity'))\n    energy.append(glcm_feature(glcm, 'energy'))\n    correlation.append(glcm_feature(glcm, 'correlation'))\n    \n    data_eye[0, count] = contrast[0]\n    data_eye[1, count] = homogeneity[0]\n    data_eye[2, count] = energy[0]\n    data_eye[3, count] = correlation[0]\n    data_eye[4, count] = label\n    \n    count += 1","metadata":{"execution":{"iopub.status.busy":"2022-02-13T07:27:27.376284Z","iopub.execute_input":"2022-02-13T07:27:27.376549Z","iopub.status.idle":"2022-02-13T07:27:42.072967Z","shell.execute_reply.started":"2022-02-13T07:27:27.376522Z","shell.execute_reply":"2022-02-13T07:27:42.072009Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Export value of image feature extraction into csv file to make easier to see","metadata":{}},{"cell_type":"code","source":"df= pd.DataFrame(np.transpose(data_eye), columns = indextable)","metadata":{"execution":{"iopub.status.busy":"2022-02-13T07:27:42.074046Z","iopub.execute_input":"2022-02-13T07:27:42.074314Z","iopub.status.idle":"2022-02-13T07:27:42.080164Z","shell.execute_reply.started":"2022-02-13T07:27:42.074288Z","shell.execute_reply":"2022-02-13T07:27:42.079196Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4. Normalize Data","metadata":{}},{"cell_type":"code","source":"df","metadata":{"execution":{"iopub.status.busy":"2022-02-13T07:27:42.081085Z","iopub.execute_input":"2022-02-13T07:27:42.081343Z","iopub.status.idle":"2022-02-13T07:27:42.12034Z","shell.execute_reply.started":"2022-02-13T07:27:42.081319Z","shell.execute_reply":"2022-02-13T07:27:42.119357Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Data have different value so i normalize using min max scaler","metadata":{}},{"cell_type":"code","source":"df.describe()","metadata":{"execution":{"iopub.status.busy":"2022-02-13T07:27:42.125362Z","iopub.execute_input":"2022-02-13T07:27:42.125699Z","iopub.status.idle":"2022-02-13T07:27:42.159906Z","shell.execute_reply.started":"2022-02-13T07:27:42.125652Z","shell.execute_reply":"2022-02-13T07:27:42.158987Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\nfeatures = df.drop(['Label'], axis='columns')\nfeatures_scaler = MinMaxScaler()\nfeatures = features_scaler.fit_transform(features)\nfeatures","metadata":{"execution":{"iopub.status.busy":"2022-02-13T07:27:42.161452Z","iopub.execute_input":"2022-02-13T07:27:42.161732Z","iopub.status.idle":"2022-02-13T07:27:42.300457Z","shell.execute_reply.started":"2022-02-13T07:27:42.161706Z","shell.execute_reply":"2022-02-13T07:27:42.299339Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Concatenate the normalization data and the label data into new dataframe","metadata":{}},{"cell_type":"code","source":"data_normalization = df.copy()\ndata_normalization[['contrast', 'homogenity', 'energy', 'correlation']] = features\ndata_normalization","metadata":{"execution":{"iopub.status.busy":"2022-02-13T07:27:42.302691Z","iopub.execute_input":"2022-02-13T07:27:42.303109Z","iopub.status.idle":"2022-02-13T07:27:42.32153Z","shell.execute_reply.started":"2022-02-13T07:27:42.303064Z","shell.execute_reply":"2022-02-13T07:27:42.320609Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_normalization.describe()","metadata":{"execution":{"iopub.status.busy":"2022-02-13T07:27:42.322965Z","iopub.execute_input":"2022-02-13T07:27:42.323262Z","iopub.status.idle":"2022-02-13T07:27:42.355387Z","shell.execute_reply.started":"2022-02-13T07:27:42.323226Z","shell.execute_reply":"2022-02-13T07:27:42.354417Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x = data_normalization.drop(['Label'], axis='columns')\ny = data_normalization.Label","metadata":{"execution":{"iopub.status.busy":"2022-02-13T07:27:42.356809Z","iopub.execute_input":"2022-02-13T07:27:42.357103Z","iopub.status.idle":"2022-02-13T07:27:42.362387Z","shell.execute_reply.started":"2022-02-13T07:27:42.357071Z","shell.execute_reply":"2022-02-13T07:27:42.361484Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5. Classification using Machine Learning Alghoritm","metadata":{}},{"cell_type":"markdown","source":"In these stage i try to using some machine learning alghoritm with some paramater to create a better model","metadata":{}},{"cell_type":"code","source":"from sklearn import svm\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\n\nmodel_params = {\n    'svm': {\n        'model': svm.SVC(gamma='auto'),\n        'params' : {\n            'C': [1,10,20,30],\n            'kernel': ['rbf','linear','poly']\n        }  \n    },\n    'random_forest': {\n        'model': RandomForestClassifier(),\n        'params' : {\n            'n_estimators': [1,5,10,50,100]\n        }\n    },\n    'logistic_regression' : {\n        'model': LogisticRegression(solver='liblinear',multi_class='auto'),\n        'params': {\n            'C': [1,5,10,50,100]\n        }\n    },\n    'KNN' : {\n        'model': KNeighborsClassifier(),\n        'params': {\n            'n_neighbors': [3,7,11,13]\n        }\n    }\n    \n}","metadata":{"execution":{"iopub.status.busy":"2022-02-13T07:27:42.363518Z","iopub.execute_input":"2022-02-13T07:27:42.363851Z","iopub.status.idle":"2022-02-13T07:27:42.654929Z","shell.execute_reply.started":"2022-02-13T07:27:42.363822Z","shell.execute_reply":"2022-02-13T07:27:42.653995Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\nscores = []\n\nfor model_name, mp in model_params.items():\n    clf =  GridSearchCV(mp['model'], mp['params'], cv=5, return_train_score=False)\n    clf.fit(x, y)\n    scores.append({\n        'model': model_name,\n        'best_score': clf.best_score_,\n        'best_params': clf.best_params_\n    })\n    \ndf_score = pd.DataFrame(scores,columns=['model','best_score','best_params'])\ndf_score","metadata":{"execution":{"iopub.status.busy":"2022-02-13T07:27:42.655999Z","iopub.execute_input":"2022-02-13T07:27:42.656273Z","iopub.status.idle":"2022-02-13T07:27:46.984565Z","shell.execute_reply.started":"2022-02-13T07:27:42.656247Z","shell.execute_reply":"2022-02-13T07:27:46.9836Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"SVM have the best score with 58%","metadata":{}},{"cell_type":"code","source":"df_score['best_score'].max()","metadata":{"execution":{"iopub.status.busy":"2022-02-13T07:27:46.986056Z","iopub.execute_input":"2022-02-13T07:27:46.986571Z","iopub.status.idle":"2022-02-13T07:27:46.993944Z","shell.execute_reply.started":"2022-02-13T07:27:46.986527Z","shell.execute_reply":"2022-02-13T07:27:46.993051Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Split data to create confusion matrix of these svm Model","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.25)","metadata":{"execution":{"iopub.status.busy":"2022-02-13T07:27:46.995288Z","iopub.execute_input":"2022-02-13T07:27:46.995847Z","iopub.status.idle":"2022-02-13T07:27:47.006476Z","shell.execute_reply.started":"2022-02-13T07:27:46.995814Z","shell.execute_reply":"2022-02-13T07:27:47.005285Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = svm.SVC(gamma='auto', C=20, kernel='poly')\nmodel.fit(x_train,y_train)","metadata":{"execution":{"iopub.status.busy":"2022-02-13T07:27:47.008017Z","iopub.execute_input":"2022-02-13T07:27:47.00854Z","iopub.status.idle":"2022-02-13T07:27:47.038766Z","shell.execute_reply.started":"2022-02-13T07:27:47.008498Z","shell.execute_reply":"2022-02-13T07:27:47.037827Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.score(x_test,y_test)","metadata":{"execution":{"iopub.status.busy":"2022-02-13T07:27:47.04043Z","iopub.execute_input":"2022-02-13T07:27:47.045375Z","iopub.status.idle":"2022-02-13T07:27:47.059182Z","shell.execute_reply.started":"2022-02-13T07:27:47.045328Z","shell.execute_reply":"2022-02-13T07:27:47.058217Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nimport seaborn as sb\ny_predicted = model.predict(x_test)\ncm = confusion_matrix(y_test,y_predicted)\nplt.figure(figsize = (10,7))\nsb.heatmap(cm, annot=True)\nplt.xlabel('Predicted')\nplt.ylabel('Truth')","metadata":{"execution":{"iopub.status.busy":"2022-02-13T07:27:47.060543Z","iopub.execute_input":"2022-02-13T07:27:47.061827Z","iopub.status.idle":"2022-02-13T07:27:47.502459Z","shell.execute_reply.started":"2022-02-13T07:27:47.061781Z","shell.execute_reply":"2022-02-13T07:27:47.501369Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"SVM model can only predict normal and cataract dataset","metadata":{}},{"cell_type":"markdown","source":"Try using neural network to create a model","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nmodel_nn = keras.Sequential([\n    keras.layers.Flatten(input_shape=(4,)),\n    keras.layers.Dense(100, activation='relu'),\n    keras.layers.Dense(4, activation='sigmoid')\n])\n\nmodel_nn.compile(optimizer='adam',\n             loss='sparse_categorical_crossentropy',\n             metrics=['accuracy'])\n\nmodel_nn.fit(x_train, y_train, epochs=50)","metadata":{"execution":{"iopub.status.busy":"2022-02-13T07:27:47.504144Z","iopub.execute_input":"2022-02-13T07:27:47.504491Z","iopub.status.idle":"2022-02-13T07:27:55.672417Z","shell.execute_reply.started":"2022-02-13T07:27:47.504449Z","shell.execute_reply":"2022-02-13T07:27:55.671597Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_nn.evaluate(x_test, y_test)\nmodel_nn.save(\"eye_model.h5\")\nfrom keras.models import load_model\nmodel1 = load_model(\"./eye_model.h5\")\nprint(model1.evaluate(x_test, y_test, verbose=0))\nprint(model1)\n","metadata":{"execution":{"iopub.status.busy":"2022-02-13T07:28:57.888548Z","iopub.execute_input":"2022-02-13T07:28:57.888934Z","iopub.status.idle":"2022-02-13T07:28:58.150498Z","shell.execute_reply.started":"2022-02-13T07:28:57.8889Z","shell.execute_reply":"2022-02-13T07:28:58.149736Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_predicted = model_nn.predict(x_test)\nprint(y_predicted[0])\ny_predicted_labels = [np.argmax(i) for i in y_predicted]\ncm = tf.math.confusion_matrix(labels=y_test, predictions=y_predicted_labels)\nplt.figure(figsize = (10,7))\nsb.heatmap(cm, annot=True, fmt='d')\nplt.xlabel('Predicted')\nplt.ylabel('Truth')","metadata":{"execution":{"iopub.status.busy":"2022-02-13T07:29:59.873338Z","iopub.execute_input":"2022-02-13T07:29:59.874007Z","iopub.status.idle":"2022-02-13T07:30:00.311311Z","shell.execute_reply.started":"2022-02-13T07:29:59.87397Z","shell.execute_reply":"2022-02-13T07:30:00.310606Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Neural Network Model have same similiar result like SVM model","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}